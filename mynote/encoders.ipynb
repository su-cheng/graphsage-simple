{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8de5c6-99c3-4094-b601-2e21a5b5601a",
   "metadata": {},
   "source": [
    "#### 基本语法\n",
    "##### init.xavier_uniform(self.weight)\n",
    "- Xavier 初始化（也称为 Glorot 初始化）：用来初始化神经网络层的权重矩阵 self.weight。具体来说，xavier_uniform 是一种权重初始化方法，它生成的权重值服从一个均匀分布，该分布的范围依据输入和输出的维度自动确定，以确保权重的初始值适合神经网络的训练\n",
    "\n",
    "##### combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "- PyTorch 中用于沿指定维度连接（拼接）两个或多个张量的函数\n",
    "- arg1：一个张量列表\n",
    "- arg2：指定了在哪个维度上进行拼接\n",
    "- dim=1：按列拼接，即行数不变，列数增加，一行一行拼接\n",
    "\n",
    "##### combined = F.relu(self.weight.mm(combined.t()))\n",
    "- combined.t()：置换操作\n",
    "- F.relu：PyTorch 中的 ReLU（Rectified Linear Unit）激活函数\n",
    "\n",
    "##### F.normalize(combined, p=2, dim=0)\n",
    "- 归一化处理\n",
    "- arg1：需要进行归一化处理的张量\n",
    "- arg2：指定范数类型\n",
    "- arg3：维度，dim=0表示对每一列进行归一化处理，也就是在南北方向上归一\n",
    "- arg4：eps，可选，在归一化过程中，如果某些向量的范数非常接近于零，可能会导致除以非常小的数值，从而引发数值不稳定性。eps 的作用就是在这种情况下增加一个很小的数，以避免除以零，默认为1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2609b-ca98-4fee-9346-4f62923ca9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a node's using 'convolutional' GraphSage approach\n",
    "    \"\"\"\n",
    "    def __init__(self, features, feature_dim, \n",
    "            embed_dim, adj_lists, aggregator,\n",
    "            num_sample=10,\n",
    "            base_model=None, gcn=False, cuda=False, \n",
    "            feature_transform=False): \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.feat_dim = feature_dim\n",
    "        self.adj_lists = adj_lists\n",
    "        self.aggregator = aggregator\n",
    "        self.num_sample = num_sample\n",
    "        if base_model != None:\n",
    "            self.base_model = base_model\n",
    "\n",
    "        self.gcn = gcn\n",
    "        self.embed_dim = embed_dim\n",
    "        self.cuda = cuda\n",
    "        self.aggregator.cuda = cuda\n",
    "        self.weight = nn.Parameter(\n",
    "                torch.FloatTensor(embed_dim, self.feat_dim if self.gcn else 2 * self.feat_dim))\n",
    "        init.xavier_uniform(self.weight)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        \"\"\"\n",
    "        Generates embeddings for a batch of nodes.\n",
    "\n",
    "        nodes     -- list of nodes\n",
    "        \"\"\"\n",
    "        neigh_feats = self.aggregator.forward(nodes, [self.adj_lists[int(node)] for node in nodes], \n",
    "                self.num_sample)\n",
    "        if not self.gcn:\n",
    "            if self.cuda:\n",
    "                self_feats = self.features(torch.LongTensor(nodes).cuda())\n",
    "            else:\n",
    "                self_feats = self.features(torch.LongTensor(nodes))\n",
    "            combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "        else:\n",
    "            combined = neigh_feats\n",
    "        combined = F.relu(self.weight.mm(combined.t()))\n",
    "        # L2范数归一化\n",
    "        combined = F.normalize(combined, p=2, dim=0)\n",
    "        return combined\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsage",
   "language": "python",
   "name": "graphsage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
